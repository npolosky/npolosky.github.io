<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by TEMPLATED
http://templated.co
Released for free under the Creative Commons Attribution License

Name       : EarthyBlue 
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20140215

-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title></title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900|Quicksand:400,700|Questrial" rel="stylesheet" />
<link href="custom.css" rel="stylesheet" type="text/css" media="all" />
<link href="fonts.css" rel="stylesheet" type="text/css" media="all" />

<!--[if IE 6]><link href="default_ie6.css" rel="stylesheet" type="text/css" /><![endif]-->

</head>
<body>
<div id="headshot-wrapper" class="headshot">
	<img src="images/headshot3.jpg" class="profile-pic"/>
</div>
<div id="header-wrapper">
	<div id="header" class="container">
		<div id="logo">
			<h1><a href="#">Nicholas Polosky</a></h1>
			<div id="menu">
				<ul>
					<li class="active"><a href="#" accesskey="1" title="">Homepage</a></li>
					<li><a href="#about" accesskey="2" title="">About Me</a></li>
					<li><a href="#projects" accesskey="3" title="">Projects</a></li>
					<li><a href="#pubs" accesskey="4" title="">Publications</a></li>
					<li><a href="#contact" accesskey="5" title="">Contact</a></li>
				</ul>
			</div>
		</div>
	</div>
</div>
<div id="about" class="wrapperWhite">
	<div id="aboutHead" class="subheaderWhite">
		<h1>About Me</h1>
	</div>
	<div id="aboutPage" class="subpage-wrapperWhite">
		<p> I am currently employed as an Associate Computer Scientist/Engineer III in the 
			Marconi-Rosenblatt AI/ML Innovation Lab at <a href="http://www.androcs.com/wp/" target="_blank">ANDRO Computational 
			Solutions LLC</a>, a defense contracting firm in Rome, NY. At ANDRO, I lead a team of engineers working to build a 
			vision-based collision avoidance and navigation subsystem for autonomous UAV applications. Our solution combines
			traditional vision-based autonomy components with machine learning based perception modules - reaping the benefits
			of robustness and generalization from both approaches. The subsystem is powered by optimized CUDA C++ code and 
			hardware accelerated vision models deployed upon an embedded NVIDIA Jetson platform, using TensorRT for further 
			model optimization. <a href="https://romesentinel.com/stories/andro-awarded-11m-navy-contract,109249" target="_blank"> Link to project press release.</a>
			<br><br>
			In 2021 I graduated with a Masters in Computer Science from <a href="https://www.cics.umass.edu/" target="_blank">University of 
			Massachusetts at Amherst</a>, focusing on reinforcement learning (RL). During my time at UMass, I was fortunate enough to conduct research with 
			<a href="https://groups.cs.umass.edu/shlomo/" target="_blank">Dr. Shlomo Zilberstein</a> on safe AI methods for 
			avoiding "dead ends" in online planning and RL. My Masters work culminated with my research on offline reinforcement learning
			methods for learning constrained MDPs, during which I was advised by Professors 
			<a href="https://www.cics.umass.edu/people/fiterau-brostean-ina" target="_blank"> Ina Fiterau</a> & 
			<a href="http://www.inf.ufrgs.br/~bsilva/" target="_blank"> Bruno Castro da Silva</a>. Our work, "<em>Constrained Offline Policy 
			Optimization</em>", introduces a novel constrained policy projection algorithm, which, given a reward optimal policy, will find 
			the cost-feasible policy that is closest to the provided reward maximizing policy. This work will be featured in <u>ICML 2022</u>.
			<br><br>
			In May of 2017 I graduated from Cornell University with a BS in Computer Science and thereafter worked full time at ANDRO,
			working on projects involving automatic modulation classification and multi-task learning for signal intelligence prior to 
			working on my current autonomy project.</p>
		<div id = "researchList">
			<p>Some of my research interests include:</p>
			<ul style="list-style-type:disc;">
				<li> Sample Efficient Reinforcement Learning </li>
				<li> Constrained Reinforcement Learning </li>
				<li> Convex Analysis/Optimization </li>
				<li> Autonomous UAV </li>
				<li> Vision-based Navigation </li>
			</ul>
		</div>
		<div id = "selfStudyList">
			<p>Some of my self-study interests include:</p>
			<ul style="list-style-type:disc;">
				<li> Mathematical Analysis, Fourier Analysis, & Functional Analysis </li>
				<li> Philosophy </li>
				<li> Nutrition & Health </li>
			</ul>
		</div>
	</div>
</div>
<div id="projects" class="wrapperBlue">
	<div id="projectsHead" class="subheaderBlue">
		<h1>Projects</h1>
	</div>
	<div id="projectsPage" class="subpage-wrapperBlue">
		<!-- <p> What I am currently working on ... </p> -->
		<h2>Deep Reinforcement Learning based Autonomous Unmanned Aeriel Vehicles</h2>
		<p>At ANDRO, I lead a team of engineers working to build a vision-based collision avoidance and navigation subsystem for 
			autonomous UAV application for the US Navy. We use vision-based autonomy algorithms to aid in navigating a UAV through tactical environments in GPS denied or lost data link scenarios. 
			Additionally, to enhance human-machine teaming, we have developed vision-based natural user interfaces (NUIs) which will allow humans to interface with the UAV via natural gestures (hand signals) and chromatic symbols.</p>
		<h2>Constrained Offline Policy Optimization</h2>
		<p>In this work we introduce Constrained Offline Policy Optimization (COPO), an offline policy optimization algorithm for learning in MDPs with cost constraints. COPO is built upon a novel offline cost-projection method, which we formally derive and analyze. Our method improves upon the state-of-the-art in offline constrained policy optimization by explicitly accounting for distributional shift and by offering non-asymptotic confidence bounds on the cost of a policy. These formal properties are superior to those of existing techniques, which only guarantee convergence to a point estimate. We formally analyze our method and empirically demonstrate that it achieves state-of-the-art performance on discrete and continuous control problems, while offering the aforementioned improved, stronger, and more robust theoretical guarantees.</p>
		<h2> Mitigating Overestimation and Distributional Shift in Offline Reinforcement Learning </h2>
		<p>The offline reinforcement learning setting - learning policies from a static data set - introduces challenges associated with the inability to sample data from the learned policy. Among such challenges, overestimation of state-action values and distributional shift are the most detrimental to learning policies that perform well once deployed. In this work, we introduce a novel offline learning algorithm that directly addresses both overestimation and distributional shift, without restricting value estimates to the data distribution. Our algorithm, entitled Initial and Semi-Implicit Q-Learning (ISIQL), learns using value targets constructed from a mixture of estimates from both the data distribution and the current policy's action distribution, thereby allowing for policy improvement outside of the behavior distribution when possible. Our value objective additionally incorporates an initial state-action value term, which we show, allows for mitigation of distributional shift. We motivate the use of these learning components by connecting to prior work, and show various ways a stochastic policy may be extracted from the learned value functions. Lastly, we show that the ISIQL algorithm achieves state-of-the-art performance on online MuJoCo benchmark tasks and offline D4RL data sets, most notably offering a 10% performance gain in offline locomotion and maze tasks. </p>
		<h2>Intelligent Signal Detector and Classifer</h2>
		<p>At ANDRO, our team is in the process of devloping a machine learning based RF signal detector and classifier for the Army. The envisioned finished final product should aid EM spectrum analysts in signal identification by providing a multitude of estimated signal characteristics to the user simultaneously. Our approach builds off of our automatic modulation classification (AMC) technology by extending the solution to a multi-task learning paradigm.</p>
	</div>
</div>
<div id="pubs" class="wrapperWhite">
	<div id="pubsWrapper" class="subheaderWhite">
		<h1 >Publications</h1>
	</div>
	<div id="pubsWrapper" class="subpage-wrapperWhite">
		<div id="journals">
			<h2>Journals</h2>
			<ul style="list-style-type:disc;">
				<li> J. Jagannath, <strong>N. Polosky</strong>, A. Jagannath, F. Restuccia, T. Melodia, "Machine Learning for Wireless Communications in the Internet of Things: A Comprehensive Survey," <strong>Ad Hoc Networks (Elsevier)</strong> vol. 93, pp 101913, June 2019. <a href="pdfs/Jagannath19ADH_ML.pdf" target="_blank">[pdf]</a><a href="bibs/Jagannath19ADH_ML.bib" target="_blank">[bibtex]</a></li>
			</ul>
		</div>
		<div id="conferences">
			<h2>Conferences</h2>
			<ul style="list-style-type:disc;">
				<li> <strong>N. Polosky</strong>, B. C. da Silva, I. Fiterau, J. Jagannath, “Constrained Offline Policy Optimization,” in <strong>International Conference on Machine Learning (ICML)</strong>, Baltimore, MD, USA, July 2022. <a href="pdfs/Polosky22ICML.pdf" target="_blank">[pdf]</a></li>
				<li> <strong>N. Polosky</strong>, T. Gwin, S. Furman, P. Barhanpurkar, J. Jagannath, “Machine Learning Subsystem for Autonomous Collision Avoidance on a small UAS with Embedded GPU,” in <strong> IEEE International Workshop on Communication and Networking for Swarms Robotics</strong>, Virtual, January 2022. <a href="pdfs/PoloskyRobocom22.pdf" target="_blank">[pdf]</a><a href="bibs/PoloskyRobocom22.bib" target="_blank">[bibtex]</a> </li>
				<li> J. Jagannath, <strong>N. Polosky</strong>, D. O’Connor, L. Theagarajan, B. Sheaffer, S. Foulke, P. Varshney, “Artificial Neural Network based Automatic Modulation Classifier for Software Defined Radios,” in <strong>Proc. of IEEE International Conference on Communications (ICC)</strong>, Kansas City, MO, USA, May 2018. <a href="pdfs/Jagannath18ICC.pdf" target="_blank">[pdf]</a><a href="bibs/Jagannath18ICC.bib" target="_blank">[bibtex]</a></li>
				<li> <strong>N. Polosky</strong>, J. Jagannath, D. O'Connor, H. Saarinen, S. Foulke, “Artificial Neural Network with Electroencephalogram Sensors for Brainwave Interpretation: Brain-Observer-Indicator Development Challenges,” in <strong>Proc. of 13th International Conference & Expo on Emerging Technologies for a Smarter World (CEWIT)</strong>, Stony Brook, NY, USA, November 2017. <a href="pdfs/Polosky17CEWIT.pdf" target="_blank">[pdf]</a><a href="bibs/Polosky17CEWIT.bib" target="_blank">[bibtex]</a></li>
				<li> J. Jagannath, D. O'Connor, <strong>N. Polosky</strong>, B. Sheaffer, L. N. Theagarajan, S. Foulke, P. K. Varshney, S. P. Reichhart, "Design and Evaluation of Hierarchical Hybrid Automatic Modulation Classifier using Software Defined Radios," in <strong>Proc. of IEEE Annual Computing and Communication Workshop and Conference (CCWC)</strong>, Las Vegas, NV, USA, January 2017. <a href="pdfs/Jagannath17CCWC.pdf" target="_blank">[pdf]</a><a href="bibs/Jagannath17CCWC.bib" target="_blank">[bibtex]</a></li>
			</ul>
		</div>
		<div id="bookChapters">
			<h2>Invited Book Chapters</h2>
			<ul style="list-style-type:disc;">
				<li> J. Jagannath, <strong>N. Polosky</strong>, A. Jagannath, F. Restuccia, T. Melodia, “Neural Networks for Signal Intelligence: Theory and Practice” in <strong>Machine Learning for Future Wireless Communications</strong>, Eds. D. L. Luo, Wiley - IEEE Series, November 2019, ISBN: 9781119562252.<a href="pdfs/Jagannath19MLBook_Chapter.pdf" target="_blank">[pdf]</a><a href="bibs/Jagannath19MLBook_Chapter.bib" target="_blank">[bibtex]</a></li>
			</ul>
		</div>
		<div id="patents">
			<h2>Patents</h2>
			<ul style="list-style-type:disc;">
				<li>Vertebral assist spinal medical device. U.S. Patent Number US 10,966,757 B2. <strong>Patent Granted</strong>.</li>
				<li>Machine learning framework for control of autonomous agent operating in dynamic environment. April 2020. Provisional Patent.</li>
				<li>Multi-task learning neural network framework for RF spectrum sensing and classification.  April 2020. Provisional Patent.</li>
			</ul>
		</div>
		<div id="reviewservice">
			<h2>Review Service</h2>
			<ul style="list-style-type:disc;">
				<li>International Conference on Machine Learning (ICML)</li>
				<li>IEEE International Conference on Communications (ICC)</li>
			</ul>
		</div>
	</div>
</div>
<div id="contact" class="wrapperBlue">
	<div id="contactHead" class="subheaderBlue">
		<h1>Contact</h1>
	</div>
	<div id="contactPage" class="subpage-wrapperBlue">
		<div id="email">
			<p>Email: poloskynick (at) gmail (dot) com</p>
		</div>
		<div id="linkedin">
			<p>LinkedIn: <a href="https://www.linkedin.com/in/nicholas-polosky-131222b4/" target="_blank">HERE</a></p>
		</div>
		<div id="googlescholar">
			<p>Google Scholar: <a href="https://scholar.google.com/citations?user=SL01itkAAAAJ&hl=en" target="_blank">HERE</a></p>
		</div>
		<div id="researchgate">
			<p>ResearchGate: <a href="https://www.researchgate.net/profile/Nicholas_Polosky" target="_blank">HERE</a></p>
		</div>
	</div>
</div>
</body>
</html>
